{"cells":[{"cell_type":"markdown","id":"8ccff89a","metadata":{"id":"8ccff89a"},"source":["### Required libraries"]},{"cell_type":"code","execution_count":11,"id":"d9af96bc","metadata":{"id":"d9af96bc","executionInfo":{"status":"ok","timestamp":1759025741191,"user_tz":-330,"elapsed":7,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}}},"outputs":[],"source":["import pandas as pd # The correct package name is pandas, not pandans.\n","import numpy as np # The correct package name is numpy, not n.\n","import matplotlib.pyplot as plt # The correct package name is matplotlib, not m.\n","import seaborn as sns # The correct package name is seaborn, not s.\n","import sklearn as sk # scikitlearn is not a valid package name. The correct import for scikit-learn is:\n","import tensorflow as tf # TensorFlow is the correct package name.\n","import keras # Keras is the correct package name.\n","import zipfile # The correct package name is zipfile, not z.\n","import shutil # The correct package name is shutil, not sh.\n","import os # The correct package name is os, not o.\n","import pickle # The correct package name is pickle, not p."]},{"cell_type":"code","execution_count":12,"id":"b5faae8c","metadata":{"id":"b5faae8c","executionInfo":{"status":"ok","timestamp":1759025743627,"user_tz":-330,"elapsed":6,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}}},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","from tensorflow.keras import layers, models, applications\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2, InceptionV3, EfficientNetB4\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"]},{"cell_type":"markdown","id":"b5303f8b","metadata":{"id":"b5303f8b"},"source":["### Data Preprocessing & Augmentation"]},{"cell_type":"code","source":["# !unzip /content/Dataset.zip"],"metadata":{"id":"cMmzhmwjFSAb","executionInfo":{"status":"ok","timestamp":1759025745510,"user_tz":-330,"elapsed":14,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}}},"id":"cMmzhmwjFSAb","execution_count":13,"outputs":[]},{"cell_type":"code","execution_count":14,"id":"202ecb0b","metadata":{"id":"202ecb0b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759025746651,"user_tz":-330,"elapsed":316,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}},"outputId":"7874fc63-33ec-46dd-a8c4-9285585b837e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 4984 images belonging to 11 classes.\n","Found 215 images belonging to 11 classes.\n","Found 3124 images belonging to 11 classes.\n","Classes: ['animal fish', 'animal fish bass', 'fish sea_food black_sea_sprat', 'fish sea_food gilt_head_bream', 'fish sea_food hourse_mackerel', 'fish sea_food red_mullet', 'fish sea_food red_sea_bream', 'fish sea_food sea_bass', 'fish sea_food shrimp', 'fish sea_food striped_red_mullet', 'fish sea_food trout']\n","Number of classes: 11\n"]}],"source":["# Define constants\n","IMG_HEIGHT = 224\n","IMG_WIDTH = 224\n","BATCH_SIZE = 32\n","\n","# Data augmentation and preparation\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest',\n","    validation_split=0.2\n",")\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Assuming 'fish_data' contains your dataset with category-based folders\n","train_generator = train_datagen.flow_from_directory(\n","    r'/content/images.cv_jzk6llhf18tm3k0kyttxz/data/train',\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='training'\n",")\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    r'/content/images.cv_jzk6llhf18tm3k0kyttxz/data/val',\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    subset='validation'\n",")\n","\n","# If you have a separate test set\n","test_generator = test_datagen.flow_from_directory(\n","    r'/content/images.cv_jzk6llhf18tm3k0kyttxz/data/test',\n","    target_size=(IMG_HEIGHT, IMG_WIDTH),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical'\n",")\n","\n","# Get class names\n","class_names = list(train_generator.class_indices.keys())\n","num_classes = len(class_names)\n","\n","print(\"Classes:\", class_names)\n","print(\"Number of classes:\", num_classes)"]},{"cell_type":"markdown","id":"b651be16","metadata":{"id":"b651be16"},"source":["### Build CNN From Scratch"]},{"cell_type":"code","execution_count":15,"id":"5d5c3dc8","metadata":{"id":"5d5c3dc8","outputId":"dcf0bfb8-f52a-4d37-f8a7-207a61f41c5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759026774882,"user_tz":-330,"elapsed":310545,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713ms/step - accuracy: 0.2471 - loss: 2.1372"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 766ms/step - accuracy: 0.2476 - loss: 2.1357 - val_accuracy: 0.5365 - val_loss: 1.4564\n","Epoch 2/50\n","\u001b[1m  1/155\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 85ms/step - accuracy: 0.5000 - loss: 1.3651"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 1.3651 - val_accuracy: 0.5156 - val_loss: 1.4056\n","Epoch 3/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716ms/step - accuracy: 0.5098 - loss: 1.3667"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 747ms/step - accuracy: 0.5099 - loss: 1.3663 - val_accuracy: 0.6979 - val_loss: 1.1120\n","Epoch 4/50\n","\u001b[1m  1/155\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 79ms/step - accuracy: 0.6875 - loss: 1.5231"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.6875 - loss: 1.5231 - val_accuracy: 0.7448 - val_loss: 0.9511\n","Epoch 5/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702ms/step - accuracy: 0.6382 - loss: 1.0130"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 734ms/step - accuracy: 0.6383 - loss: 1.0126 - val_accuracy: 0.7656 - val_loss: 0.7005\n","Epoch 6/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.4688 - loss: 0.9903 - val_accuracy: 0.7500 - val_loss: 0.7202\n","Epoch 7/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.7352 - loss: 0.7402"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 438ms/step - accuracy: 0.7352 - loss: 0.7402 - val_accuracy: 0.8385 - val_loss: 0.4663\n","Epoch 8/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7812 - loss: 0.4783 - val_accuracy: 0.8125 - val_loss: 0.5831\n","Epoch 9/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699ms/step - accuracy: 0.7602 - loss: 0.6451"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 733ms/step - accuracy: 0.7603 - loss: 0.6450 - val_accuracy: 0.8281 - val_loss: 0.4529\n","Epoch 10/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.8125 - loss: 0.5015 - val_accuracy: 0.7760 - val_loss: 0.5653\n","Epoch 11/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708ms/step - accuracy: 0.8173 - loss: 0.5303"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 740ms/step - accuracy: 0.8173 - loss: 0.5303 - val_accuracy: 0.8490 - val_loss: 0.3994\n","Epoch 12/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.9062 - loss: 0.3272 - val_accuracy: 0.8281 - val_loss: 0.5131\n","Epoch 13/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.8336 - loss: 0.4743"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 524ms/step - accuracy: 0.8336 - loss: 0.4743 - val_accuracy: 0.8906 - val_loss: 0.3415\n","Epoch 14/50\n","\u001b[1m  1/155\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 109ms/step - accuracy: 0.7188 - loss: 0.5928"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7188 - loss: 0.5928 - val_accuracy: 0.8906 - val_loss: 0.3390\n","Epoch 15/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 412ms/step - accuracy: 0.8521 - loss: 0.4088 - val_accuracy: 0.8594 - val_loss: 0.4057\n","Epoch 16/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8438 - loss: 0.3437 - val_accuracy: 0.8750 - val_loss: 0.3914\n","Epoch 17/50\n","\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 408ms/step - accuracy: 0.8633 - loss: 0.3892 - val_accuracy: 0.8542 - val_loss: 0.3538\n"]}],"source":["# Build CNN From Scratch\n","\n","def create_custom_cnn():\n","    model = models.Sequential([\n","        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(64, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(128, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Conv2D(128, (3, 3), activation='relu'),\n","        layers.MaxPooling2D((2, 2)),\n","        layers.Flatten(),\n","        layers.Dense(512, activation='relu'),\n","        layers.Dropout(0.5),\n","        layers.Dense(num_classes, activation='softmax')\n","    ])\n","\n","    model.compile(\n","        optimizer='adam',\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model\n","\n","# Train custom CNN\n","custom_model = create_custom_cnn()\n","custom_history = custom_model.fit(\n","    train_generator,\n","    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n","    validation_data=validation_generator,\n","    validation_steps=validation_generator.samples // BATCH_SIZE,\n","    epochs=50,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n","        tf.keras.callbacks.ModelCheckpoint('custom_cnn_fish.h5', save_best_only=True)\n","    ]\n",")\n"]},{"cell_type":"code","execution_count":16,"id":"32e200ce","metadata":{"id":"32e200ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759032587575,"user_tz":-330,"elapsed":5812677,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}},"outputId":"b733dd43-c82e-4099-fcaf-12509e26264d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8354 images belonging to 3 classes.\n","Found 2087 images belonging to 3 classes.\n","Classes: ['test', 'train', 'val']\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","\n","🚀 Training CustomCNN...\n","Epoch 1/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5645 - loss: 0.9597"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.5648 - loss: 0.9593 - val_accuracy: 0.5966 - val_loss: 0.9243 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.6002 - loss: 0.9124 - val_accuracy: 0.5966 - val_loss: 0.9090 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.5932 - loss: 0.9138 - val_accuracy: 0.5966 - val_loss: 0.9067 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.5989 - loss: 0.9070 - val_accuracy: 0.5966 - val_loss: 0.9093 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.5882 - loss: 0.9176 - val_accuracy: 0.5966 - val_loss: 0.9069 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.5874 - loss: 0.9195 - val_accuracy: 0.5966 - val_loss: 0.9067 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.5941 - loss: 0.9050 - val_accuracy: 0.5966 - val_loss: 0.9054 - learning_rate: 2.0000e-04\n","Epoch 8/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.6014 - loss: 0.9028 - val_accuracy: 0.5966 - val_loss: 0.9049 - learning_rate: 2.0000e-04\n","Epoch 9/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.5891 - loss: 0.9131 - val_accuracy: 0.5966 - val_loss: 0.9111 - learning_rate: 2.0000e-04\n","Epoch 10/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.5921 - loss: 0.9090 - val_accuracy: 0.5966 - val_loss: 0.9074 - learning_rate: 2.0000e-04\n","Epoch 11/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.5987 - loss: 0.9073 - val_accuracy: 0.5966 - val_loss: 0.9051 - learning_rate: 2.0000e-04\n","Epoch 12/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.5926 - loss: 0.9122 - val_accuracy: 0.5966 - val_loss: 0.9050 - learning_rate: 4.0000e-05\n","Epoch 13/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.6015 - loss: 0.8944 - val_accuracy: 0.5966 - val_loss: 0.9048 - learning_rate: 4.0000e-05\n","Epoch 14/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.5977 - loss: 0.9033 - val_accuracy: 0.5966 - val_loss: 0.9052 - learning_rate: 4.0000e-05\n","Epoch 15/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.5981 - loss: 0.9095 - val_accuracy: 0.5966 - val_loss: 0.9052 - learning_rate: 4.0000e-05\n","Epoch 16/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.5971 - loss: 0.9050 - val_accuracy: 0.5966 - val_loss: 0.9049 - learning_rate: 4.0000e-05\n","Epoch 17/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.5970 - loss: 0.9039 - val_accuracy: 0.5966 - val_loss: 0.9049 - learning_rate: 8.0000e-06\n","Epoch 18/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 1s/step - accuracy: 0.5962 - loss: 0.9054 - val_accuracy: 0.5966 - val_loss: 0.9050 - learning_rate: 8.0000e-06\n","\n","🚀 Training VGG16...\n","Epoch 1/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5781 - loss: 0.9471"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.5783 - loss: 0.9470 - val_accuracy: 0.5966 - val_loss: 0.9114 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.5926 - loss: 0.9157 - val_accuracy: 0.5966 - val_loss: 0.9203 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.5942 - loss: 0.9171 - val_accuracy: 0.5966 - val_loss: 0.9150 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.5849 - loss: 0.9249 - val_accuracy: 0.5966 - val_loss: 0.9197 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1s/step - accuracy: 0.5920 - loss: 0.9147 - val_accuracy: 0.5966 - val_loss: 0.9096 - learning_rate: 2.0000e-04\n","Epoch 6/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.5961 - loss: 0.9060 - val_accuracy: 0.5966 - val_loss: 0.9109 - learning_rate: 2.0000e-04\n","Epoch 7/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 1s/step - accuracy: 0.5976 - loss: 0.9071 - val_accuracy: 0.5966 - val_loss: 0.9095 - learning_rate: 2.0000e-04\n","Epoch 8/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6032 - loss: 0.9068 - val_accuracy: 0.5966 - val_loss: 0.9104 - learning_rate: 2.0000e-04\n","Epoch 9/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.5918 - loss: 0.9128 - val_accuracy: 0.5966 - val_loss: 0.9118 - learning_rate: 2.0000e-04\n","Epoch 10/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6014 - loss: 0.9023 - val_accuracy: 0.5966 - val_loss: 0.9098 - learning_rate: 2.0000e-04\n","Epoch 11/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.6032 - loss: 0.9006 - val_accuracy: 0.5966 - val_loss: 0.9098 - learning_rate: 4.0000e-05\n","Epoch 12/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 1s/step - accuracy: 0.5918 - loss: 0.9086 - val_accuracy: 0.5966 - val_loss: 0.9105 - learning_rate: 4.0000e-05\n","\n","🚀 Training ResNet50...\n","Epoch 1/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5616 - loss: 0.9673"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.5617 - loss: 0.9670 - val_accuracy: 0.5966 - val_loss: 0.9378 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5882 - loss: 0.9362 - val_accuracy: 0.5966 - val_loss: 0.9094 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.6080 - loss: 0.8996 - val_accuracy: 0.5966 - val_loss: 0.9074 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 1s/step - accuracy: 0.6048 - loss: 0.8981 - val_accuracy: 0.5966 - val_loss: 0.9085 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.6065 - loss: 0.9085 - val_accuracy: 0.5966 - val_loss: 0.9186 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5899 - loss: 0.9176 - val_accuracy: 0.5966 - val_loss: 0.9225 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5914 - loss: 0.9179 - val_accuracy: 0.5966 - val_loss: 0.9077 - learning_rate: 2.0000e-04\n","Epoch 8/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.6024 - loss: 0.8981 - val_accuracy: 0.5966 - val_loss: 0.9095 - learning_rate: 2.0000e-04\n","\n","🚀 Training MobileNetV2...\n","Epoch 1/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5377 - loss: 1.1055"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 2s/step - accuracy: 0.5379 - loss: 1.1042 - val_accuracy: 0.5989 - val_loss: 0.9319 - learning_rate: 0.0010\n","Epoch 2/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.5970 - loss: 0.9118 - val_accuracy: 0.5961 - val_loss: 0.9375 - learning_rate: 0.0010\n","Epoch 3/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.5867 - loss: 0.9224 - val_accuracy: 0.5985 - val_loss: 0.9285 - learning_rate: 0.0010\n","Epoch 4/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.5937 - loss: 0.9134 - val_accuracy: 0.5970 - val_loss: 0.9302 - learning_rate: 0.0010\n","Epoch 5/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.5958 - loss: 0.9108 - val_accuracy: 0.5966 - val_loss: 0.9232 - learning_rate: 0.0010\n","Epoch 6/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.5954 - loss: 0.9082 - val_accuracy: 0.5966 - val_loss: 0.9223 - learning_rate: 0.0010\n","Epoch 7/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.5957 - loss: 0.9066 - val_accuracy: 0.5966 - val_loss: 0.9211 - learning_rate: 0.0010\n","Epoch 8/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.5933 - loss: 0.9101 - val_accuracy: 0.5966 - val_loss: 0.9192 - learning_rate: 0.0010\n","Epoch 9/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 1s/step - accuracy: 0.5954 - loss: 0.8993 - val_accuracy: 0.5966 - val_loss: 0.9242 - learning_rate: 0.0010\n","Epoch 10/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 1s/step - accuracy: 0.5961 - loss: 0.9046 - val_accuracy: 0.5966 - val_loss: 0.9219 - learning_rate: 0.0010\n","Epoch 11/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.5991 - loss: 0.9002 - val_accuracy: 0.5966 - val_loss: 0.9291 - learning_rate: 0.0010\n","Epoch 12/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 1s/step - accuracy: 0.5929 - loss: 0.9067 - val_accuracy: 0.5966 - val_loss: 0.9251 - learning_rate: 2.0000e-04\n","Epoch 13/30\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 1s/step - accuracy: 0.6029 - loss: 0.8900 - val_accuracy: 0.5966 - val_loss: 0.9268 - learning_rate: 2.0000e-04\n","\n","✅ Best Model: MobileNetV2 (Val Accuracy: 0.5989)\n","📂 Saved as models/best_model.h5\n"]}],"source":["import os\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2, InceptionV3, EfficientNetB0\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import shutil\n","\n","# Ensure models directory exists\n","os.makedirs('models', exist_ok=True)\n","\n","DATA_DIR = r'/content/images.cv_jzk6llhf18tm3k0kyttxz/data'\n","IMG_SIZE = (224, 224)\n","BATCH_SIZE = 100\n","EPOCHS = 30\n","\n","# 🔹 Data Generators (without using create_data_generators)\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2   # split train/val\n",")\n","\n","val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n","\n","train_gen = train_datagen.flow_from_directory(\n","    DATA_DIR,\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"categorical\",\n","    color_mode=\"rgb\",      # <-- Force RGB\n","    subset=\"training\"\n",")\n","\n","val_gen = val_datagen.flow_from_directory(\n","    DATA_DIR,\n","    target_size=IMG_SIZE,\n","    batch_size=BATCH_SIZE,\n","    class_mode=\"categorical\",\n","    color_mode=\"rgb\",      # <-- Force RGB\n","    subset=\"validation\"\n",")\n","\n","\n","\n","NUM_CLASSES = len(train_gen.class_indices)\n","CLASS_NAMES = list(train_gen.class_indices.keys())\n","print(f\"Classes: {CLASS_NAMES}\")\n","\n","# ------------------- Models -------------------\n","def build_custom_cnn(input_shape, num_classes):\n","    model = models.Sequential([\n","        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n","        layers.MaxPooling2D(2,2),\n","        layers.Conv2D(64, (3,3), activation='relu'),\n","        layers.MaxPooling2D(2,2),\n","        layers.Conv2D(128, (3,3), activation='relu'),\n","        layers.MaxPooling2D(2,2),\n","        layers.Flatten(),\n","        layers.Dropout(0.5),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","def build_transfer_model(base_model, input_shape, num_classes):\n","    base = base_model(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base.trainable = False\n","    model = models.Sequential([\n","        base,\n","        layers.GlobalAveragePooling2D(),\n","        layers.Dropout(0.3),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(num_classes, activation='softmax')\n","    ])\n","    return model\n","\n","# Define models\n","model_configs = {\n","    'CustomCNN': build_custom_cnn((*IMG_SIZE, 3), NUM_CLASSES),\n","    'VGG16': build_transfer_model(VGG16, (*IMG_SIZE, 3), NUM_CLASSES),\n","    'ResNet50': build_transfer_model(ResNet50, (*IMG_SIZE, 3), NUM_CLASSES),\n","    'MobileNetV2': build_transfer_model(MobileNetV2, (*IMG_SIZE, 3), NUM_CLASSES),\n","}\n","\n","# ------------------- Training -------------------\n","best_acc = 0\n","best_model_name = \"\"\n","\n","for name, model in model_configs.items():\n","    print(f\"\\n🚀 Training {name}...\")\n","\n","    model.compile(\n","        optimizer=Adam(learning_rate=0.001),\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    callbacks = [\n","        ModelCheckpoint(f'models/{name}.h5', save_best_only=True, monitor='val_accuracy'),\n","        EarlyStopping(patience=5, restore_best_weights=True),\n","        ReduceLROnPlateau(factor=0.2, patience=3)\n","    ]\n","\n","    history = model.fit(\n","        train_gen,\n","        validation_data=val_gen,\n","        epochs=EPOCHS,\n","        callbacks=callbacks,\n","        verbose=1\n","    )\n","\n","    # Track best model\n","    val_acc = max(history.history['val_accuracy'])\n","    if val_acc > best_acc:\n","        best_acc = val_acc\n","        best_model_name = name\n","\n","print(f\"\\n✅ Best Model: {best_model_name} (Val Accuracy: {best_acc:.4f})\")\n","\n","# Save best model\n","shutil.copy(f'models/{best_model_name}.h5', 'models/best_model.h5')\n","print(\"📂 Saved as models/best_model.h5\")\n"]},{"cell_type":"code","execution_count":null,"id":"9e5b39ae","metadata":{"id":"9e5b39ae"},"outputs":[],"source":["ModelCheckpoint(f'models/{name}.h5', save_best_only=True, monitor='val_accuracy')"]},{"cell_type":"markdown","id":"eb2d81d7","metadata":{"id":"eb2d81d7"},"source":["### Transfer Learning (Pre-trained Models)"]},{"cell_type":"code","execution_count":21,"id":"80f1526b","metadata":{"id":"80f1526b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759035236289,"user_tz":-330,"elapsed":2250734,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}},"outputId":"27c32c39-b8e5-46e3-a282-12d399b67b37"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 1s/step - accuracy: 0.4678 - loss: 6.2202 - val_accuracy: 0.5956 - val_loss: 1.7629\n","Epoch 2/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.4935 - loss: 1.4553 - val_accuracy: 0.5903 - val_loss: 1.0227\n","Epoch 3/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 1s/step - accuracy: 0.5529 - loss: 1.1041 - val_accuracy: 0.5970 - val_loss: 2.2537\n","Epoch 4/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5125 - loss: 1.4028 - val_accuracy: 0.5946 - val_loss: 0.9733\n","Epoch 5/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5151 - loss: 1.0142 - val_accuracy: 0.5961 - val_loss: 1.1048\n","Epoch 6/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5405 - loss: 0.9976 - val_accuracy: 0.3033 - val_loss: 1.3635\n","Epoch 7/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5287 - loss: 1.0238 - val_accuracy: 0.5707 - val_loss: 0.9678\n","Epoch 8/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.5528 - loss: 0.9690 - val_accuracy: 0.5443 - val_loss: 0.9637\n","Epoch 9/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.5314 - loss: 1.0847 - val_accuracy: 0.5922 - val_loss: 0.9808\n","Epoch 10/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 1s/step - accuracy: 0.5730 - loss: 0.9408 - val_accuracy: 0.5798 - val_loss: 0.9410\n","Epoch 11/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 1s/step - accuracy: 0.5808 - loss: 0.9442 - val_accuracy: 0.5256 - val_loss: 0.9511\n","Epoch 12/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 1s/step - accuracy: 0.5464 - loss: 0.9800 - val_accuracy: 0.5961 - val_loss: 0.9983\n","Epoch 13/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5475 - loss: 0.9664 - val_accuracy: 0.5467 - val_loss: 0.9447\n","Epoch 14/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5705 - loss: 0.9513 - val_accuracy: 0.4940 - val_loss: 0.9911\n","Epoch 15/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5518 - loss: 0.9627 - val_accuracy: 0.5352 - val_loss: 0.9600\n","Epoch 16/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 1s/step - accuracy: 0.5744 - loss: 0.9307 - val_accuracy: 0.5405 - val_loss: 0.9492\n","Epoch 17/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5453 - loss: 0.9595 - val_accuracy: 0.5707 - val_loss: 0.9403\n","Epoch 18/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5670 - loss: 0.9449 - val_accuracy: 0.5951 - val_loss: 0.9865\n","Epoch 19/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 1s/step - accuracy: 0.5739 - loss: 0.9652 - val_accuracy: 0.5855 - val_loss: 0.9310\n","Epoch 20/20\n","\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 1s/step - accuracy: 0.5953 - loss: 0.9122 - val_accuracy: 0.4935 - val_loss: 0.9795\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras import Model\n","from tensorflow.keras import layers\n","\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n","base_model.trainable = False  # freeze layers\n","\n","x = layers.Flatten()(base_model.output)\n","x = layers.Dense(256, activation='relu')(x)\n","output = layers.Dense(3, activation='softmax')(x) # Using 3 classes based on cell 32e200ce output\n","\n","resnet_model = Model(inputs=base_model.input, outputs=output)\n","resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history_resnet = resnet_model.fit(train_gen, validation_data=val_gen, epochs=20)\n","resnet_model.save(\"models/resnet_fish.h5\")"]},{"cell_type":"code","execution_count":null,"id":"3249bb5c","metadata":{"id":"3249bb5c","executionInfo":{"status":"aborted","timestamp":1759025735748,"user_tz":-330,"elapsed":18472,"user":{"displayName":"PRAKASH","userId":"03302981588580007272"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}